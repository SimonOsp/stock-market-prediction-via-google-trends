{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "NumPy - Import the data.\n",
    "\n",
    "XGBoost - ML package used.\n",
    "\n",
    "train_test_split - Split the data into a _training and a testing_ set.\n",
    "\n",
    "RandomizedSearchCV / GridSearchCV - Figure out the best _hyperparameters_.\n",
    "\n",
    "f1_score / recall_score / accuracy_score - Metrics used to give the various models scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data \n",
    "The data is loaded in—using NumPy—and the various sections are allocated (X and y). X = features, y = targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"ml_models/weekly_delta_binary.csv\", delimiter=\",\", skiprows=1)\n",
    "\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data\n",
    "Split the data into a 80/20 train-test split. No shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model\n",
    "Just the most basic model, without any adjustments of the hyperparameters. However, not optimal, since the hyperparameters haven't been optimized, and is thereby most likely overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall:  0.77\n",
      "Test F1 Average:  0.6968325791855204\n",
      "Test Accuracy:  0.6104651162790697\n"
     ]
    }
   ],
   "source": [
    "# xgb_clf = xgb.XGBClassifier(objective=\"multi:softmax\")\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "xgb_model = xgb_clf.fit(X_train, y_train)\n",
    "y_train_preds = xgb_model.predict(X_train)\n",
    "y_test_preds = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"Test Recall: \", recall_score(y_test, y_test_preds))\n",
    "print(\"Test F1 Average: \", f1_score(y_test, y_test_preds))\n",
    "print(\"Test Accuracy: \", accuracy_score(y_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most important feature\n",
    "Features are given weights on how important they are for the predictions, this outputs the most important feature, along with it's weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 0.031139895\n"
     ]
    }
   ],
   "source": [
    "for index, feature in enumerate(xgb_model.feature_importances_):\n",
    "    if feature == xgb_model.feature_importances_.max():\n",
    "        print(index, feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best parameters.\n",
    "Use `GridSearchCV` with Google Cloud to get the actual best parameters, `RandomizedSearchCV` only checks randomly (so it doesn't use too much computational power, because `GridSearchCV` can take days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 45s, sys: 2.46 s, total: 4min 47s\n",
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "parameters = {\"learning_rate\": [0.1, 0.01, 0.001],\n",
    "               \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
    "               \"max_depth\": [2, 4, 7, 10],\n",
    "               \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n",
    "               \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "               \"reg_alpha\": [0, 0.5, 1],\n",
    "               \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "               \"min_child_weight\": [1, 3, 5, 7],\n",
    "               \"n_estimators\": [100, 250, 500, 1000]}\n",
    "\n",
    "xgb_rscv = RandomizedSearchCV(xgb_clf, param_distributions=parameters, scoring=\"accuracy\",\n",
    "                             cv=10, verbose=3)\n",
    "\n",
    "model_xgboost = xgb_rscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best parameters\n",
    "Insert the best parameters found by `RandomizedSearchCV` (or `GridSearchCV`), and test it. Check if the metric scores have improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall:  0.79\n",
      "Test F1 Average:  0.6556016597510373\n",
      "Test Accuracy:  0.5174418604651163\n"
     ]
    }
   ],
   "source": [
    "params = model_xgboost.best_estimator_.get_params()\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(**params)\n",
    "\n",
    "xgb_model = xgb_clf.fit(X_train, y_train)\n",
    "y_train_preds = xgb_model.predict(X_train)\n",
    "y_test_preds = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"Test Recall: \", recall_score(y_test, y_test_preds))\n",
    "print(\"Test F1 Average: \", f1_score(y_test, y_test_preds))\n",
    "print(\"Test Accuracy: \", accuracy_score(y_test, y_test_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bit748edce4d40a4eaeae1c5452b72d767c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
