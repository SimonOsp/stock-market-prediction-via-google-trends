{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Imports\n",
    "Numpy - Import the data.\n",
    "\n",
    "XGBoost - ML package used.\n",
    "\n",
    "train_test_split - Split the data into a _training and a testing_ set.\n",
    "\n",
    "RandomizedSearchCV / GridSearchCV - Figure out the best _hyperparameters_.\n",
    "\n",
    "f1_score / recall_score / accuracy_score - Metrics used to give the various models scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Load in data \n",
    "The data is loaded in—using NumPy—and the various sections are allocated (X and y). X = features, y = targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"data/processed/weekly-delta-binary-curated.csv\", delimiter=\",\")\n",
    "\n",
    "X = data[:,1:]\n",
    "y = data[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Split data\n",
    "Split the data into a 80/20 train-test split. No shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Base model\n",
    "Just the most basic model, without any adjustments of the hyperparameters. However, not optimal, since the hyperparameters haven't been optimized, and is thereby most likely overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall:  0.62\n",
      "Test F1 Average:  0.5767441860465116\n",
      "Test Accuracy:  0.4678362573099415\n",
      "Training Accuracy:  0.7090643274853801\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(learning_rate=0.001)\n",
    "\n",
    "\n",
    "xgb_model = xgb_clf.fit(X_train, y_train)\n",
    "y_train_preds = xgb_model.predict(X_train)\n",
    "y_test_preds = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"Test Recall: \", recall_score(y_test, y_test_preds))\n",
    "print(\"Test F1 Average: \", f1_score(y_test, y_test_preds))\n",
    "print(\"Test Accuracy: \", accuracy_score(y_test, y_test_preds))\n",
    "print(\"Training Accuracy: \", accuracy_score(y_train, y_train_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Annual return model\n",
    "This returns the annual return of the model and for a buy-and-hold strategy. Used for comparing algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "ticker_df = yf.download(\"^DJI\", period=\"max\", interval=\"1wk\")\n",
    "ticker_df = ticker_df.drop([\"Open\", \"High\", \"Low\", \"Adj Close\", \"Volume\"], axis=1)\n",
    "ticker_df[\"Pct_Change\"] = ticker_df[\"Close\"].pct_change()\n",
    "ticker_df.loc[:, \"Pct_Change\"] += 1\n",
    "ticker_df = ticker_df[-len(y_test_preds)-4:-4]\n",
    "ticker_df = ticker_df.reset_index()\n",
    "\n",
    "ml = 100\n",
    "bh = 100\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "while i < len(y_test_preds):\n",
    "    if y_test_preds[i] == 1:\n",
    "        ml *= ticker_df[\"Pct_Change\"][i]\n",
    "    else:\n",
    "        ml /= ticker_df[\"Pct_Change\"][i]\n",
    "        \n",
    "    if ticker_df[\"Pct_Change\"][i] >= 1:\n",
    "        j += 1\n",
    "        \n",
    "    bh *= ticker_df[\"Pct_Change\"][i]\n",
    "        \n",
    "    i += 1\n",
    "       \n",
    "ml = (ml - 100) / 100\n",
    "bh = (bh - 100) / 100\n",
    "\n",
    "ml = (1+ml) ** (1 / (len(y_test_preds)/52)) - 1\n",
    "bh = (1+bh) ** (1 / (len(y_test_preds)/52)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm Annual Return: 16.1 %\n",
      "Buy-and-hold Annual Return: 7.1 %\n",
      "Buy-and-hold Accuracy: 0.5847953216374269\n"
     ]
    }
   ],
   "source": [
    "print(\"Algorithm Annual Return:\", (ml * 100).round(1), \"%\")\n",
    "print(\"Buy-and-hold Annual Return:\", (bh * 100).round(1), \"%\")\n",
    "print(\"Buy-and-hold Accuracy:\", j / len(y_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Feature importance\n",
    "Features are given weights on how important they are for the predictions, this outputs the most important feature, along with it's weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.092999764\n"
     ]
    }
   ],
   "source": [
    "for index, feature in enumerate(xgb_model.feature_importances_):\n",
    "    if feature == xgb_model.feature_importances_.max():\n",
    "        print(index, feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Get the best parameters.\n",
    "Use `GridSearchCV` with Google Cloud to get the actual best parameters, `RandomizedSearchCV` only checks randomly (so it doesn't use too much computational power, because `GridSearchCV` can take days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "parameters = {\"learning_rate\": [0.1, 0.01, 0.001],\n",
    "               \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
    "               \"max_depth\": [2, 4, 7, 10],\n",
    "               \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n",
    "               \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "               \"reg_alpha\": [0, 0.5, 1],\n",
    "               \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "               \"min_child_weight\": [1, 3, 5, 7],\n",
    "               \"n_estimators\": [100, 250, 500, 1000]}\n",
    "\n",
    "xgb_rscv = RandomizedSearchCV(xgb_clf, param_distributions=parameters, scoring=\"accuracy\",\n",
    "                             cv=10, verbose=3)\n",
    "\n",
    "model_xgboost = xgb_rscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Best parameters\n",
    "Insert the best parameters found by `RandomizedSearchCV` (or `GridSearchCV`), and test it. Check if the metric scores have improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall:  1.0\n",
      "Test F1 Average:  0.7380073800738007\n",
      "Test Accuracy:  0.5847953216374269\n"
     ]
    }
   ],
   "source": [
    "params = model_xgboost.best_estimator_.get_params()\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(**params)\n",
    "\n",
    "xgb_model = xgb_clf.fit(X_train, y_train)\n",
    "y_train_preds = xgb_model.predict(X_train)\n",
    "y_test_preds = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"Test Recall: \", recall_score(y_test, y_test_preds))\n",
    "print(\"Test F1 Average: \", f1_score(y_test, y_test_preds))\n",
    "print(\"Test Accuracy: \", accuracy_score(y_test, y_test_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bit748edce4d40a4eaeae1c5452b72d767c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
